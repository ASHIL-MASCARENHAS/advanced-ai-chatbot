<!DOCTYPE html>
<html lang="en" class="dark">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Advanced AI Chatbot</title>

    <!--
      NETLIFY DEPLOYMENT NOTE:
      The API key is injected via "Snippet Injection" as a <meta> tag:
      <meta name="gemini-api-key" content="${GEMINI_API_KEY}">
      This is set in: Site configuration > Snippet injection
    -->

    <!-- 1. Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    
    <!-- 2. Tailwind Dark Mode Config -->
    <script>
        tailwind.config = {
            darkMode: 'class', // 'class' enables manual dark mode
            theme: {
                extend: {
                    fontFamily: {
                        sans: ['Inter', 'sans-serif'],
                    },
                    colors: {
                        dark: {
                            bg: '#121212',
                            'bg-secondary': '#1e1e1e',
                            'bg-tertiary': '#2a2a2a',
                            text: '#e0e0e0',
                            'text-secondary': '#a0a0a0',
                            border: '#3a3a3a',
                            primary: '#4f46e5',
                            'primary-hover': '#5a52d9',
                        }
                    }
                }
            }
        }
    </script>
    
    <!-- 3. Font Awesome Icons (for microphone, etc.) -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    
    <!--
      4. LOCAL DEVELOPMENT ONLY: Load API Key Config
      This file is NOT on GitHub and is ignored by .gitignore.
      The code will check if we are on "localhost" before trying to load this.
    -->
    <script>
      // Smart loader for local development
      // This prevents the 404 error on the deployed site.
      if (window.location.hostname === "localhost" || window.location.hostname === "127.0.0.1") {
        document.write('<script src="config.js" defer><\/script>');
      }
    </script>
</head>

<body class="dark:bg-dark-bg dark:text-dark-text font-sans antialiased flex flex-col h-screen">

    <!-- Header -->
    <header class="dark:bg-dark-bg-secondary dark:border-b dark:border-dark-border shadow-md p-4 flex justify-between items-center z-10">
        <h1 class="text-xl font-bold text-transparent bg-clip-text bg-gradient-to-r from-purple-400 to-indigo-600">Advanced AI Chatbot</h1>
        <div class="flex items-center space-x-4">
            <div class="flex items-center space-x-2" title="Toggle for real-time Google Search results and citations">
                <i class="fa-brands fa-google text-sm dark:text-dark-text-secondary"></i>
                <span class="text-sm dark:text-dark-text-secondary">Google Search</span>
                <input type="checkbox" id="google-search-toggle" class="toggle-checkbox relative w-10 h-5 bg-gray-300 dark:bg-dark-bg-tertiary rounded-full shadow-inner appearance-none cursor-pointer transition-colors ease-in-out duration-200 checked:bg-indigo-600">
            </div>
            <div class="flex items-center space-x-2" title="Toggle to have responses spoken aloud">
                <i class="fa-solid fa-volume-high text-sm dark:text-dark-text-secondary"></i>
                <span class="text-sm dark:text-dark-text-secondary">Voice Response</span>
                <input type="checkbox" id="voice-response-toggle" class="toggle-checkbox relative w-10 h-5 bg-gray-300 dark:bg-dark-bg-tertiary rounded-full shadow-inner appearance-none cursor-pointer transition-colors ease-in-out duration-200 checked:bg-indigo-600">
            </div>
        </div>
    </header>

    <!-- Chat Area -->
    <main id="chat-container" class="flex-1 overflow-y-auto p-4 md:p-8 space-y-4 bg-dots">
        <!-- Chat messages will be appended here -->
        <div class="chat-message bot">
            <div class="message-content">
                <p>Hello! I'm an advanced AI assistant. You can ask me questions, upload images, or enable Google Search for real-time info. How can I help you today?</p>
            </div>
        </div>
    </main>

    <!-- Input Area -->
    <footer class="dark:bg-dark-bg-secondary dark:border-t dark:border-dark-border p-4 shadow-inner">
        <div class="max-w-3xl mx-auto">
            
            <!-- Error Message Display -->
            <div id="error-message" class="hidden bg-red-100 dark:bg-red-900/30 border border-red-400 dark:border-red-700 text-red-700 dark:text-red-300 px-4 py-3 rounded-lg relative mb-3" role="alert">
                <strong class="font-bold">Error:</strong>
                <span class="block sm:inline" id="error-text">Something went wrong.</span>
            </div>
            
            <!-- Image/File Preview Area -->
            <div id="file-preview-container" class="hidden mb-2 relative w-32 h-32">
                <img id="file-preview-image" src="" alt="File preview" class="w-full h-full object-cover rounded-lg border-2 dark:border-dark-border">
                <button id="remove-file-btn" class="absolute -top-2 -right-2 bg-red-600 hover:bg-red-700 text-white rounded-full w-6 h-6 flex items-center justify-center shadow-md" title="Remove file">
                    <i class="fa-solid fa-times text-sm"></i>
                </button>
            </div>

            <!-- Input Form -->
            <form id="chat-form" class="flex items-end space-x-3">
                <input type="file" id="file-upload-input" accept="image/*,application/pdf" class="hidden">
                <button type="button" id="file-upload-btn" title="Upload Image or PDF" class="flex-shrink-0 w-12 h-12 bg-gray-200 dark:bg-dark-bg-tertiary dark:hover:bg-gray-700 text-gray-600 dark:text-dark-text-secondary hover:bg-gray-300 rounded-lg flex items-center justify-center transition-colors">
                    <i class="fa-solid fa-paperclip text-lg"></i>
                </button>

                <div class="flex-1 relative">
                    <textarea id="prompt-input" rows="1" class="w-full p-3 pr-20 bg-white dark:bg-dark-bg-tertiary dark:border-dark-border border rounded-lg shadow-inner resize-none focus:outline-none focus:ring-2 focus:ring-indigo-500 dark:focus:border-indigo-500 scrollbar-hide" placeholder="Type your message or use microphone..."></textarea>
                    
                    <button type="button" id="mic-btn" title="Use Microphone" class="absolute right-12 top-1/2 -translate-y-1/2 w-10 h-10 text-gray-500 dark:text-dark-text-secondary hover:text-indigo-600 dark:hover:text-indigo-400 rounded-full flex items-center justify-center transition-colors">
                        <i class="fa-solid fa-microphone text-lg"></i>
                    </button>
                </div>
                
                <button type="submit" id="send-btn" title="Send Message" class="flex-shrink-0 w-12 h-12 bg-indigo-600 hover:bg-indigo-700 text-white rounded-lg flex items-center justify-center transition-colors disabled:opacity-50 disabled:cursor-not-allowed">
                    <i id="send-icon" class="fa-solid fa-paper-plane text-lg"></i>
                    <i id="loading-spinner" class="fa-solid fa-spinner text-lg fa-spin hidden"></i>
                </button>
            </form>
        </div>
    </footer>

    <!-- Custom Styles -->
    <style>
        /* Custom scrollbar for chat */
        #chat-container::-webkit-scrollbar {
            width: 8px;
        }
        #chat-container::-webkit-scrollbar-track {
            background: transparent;
        }
        #chat-container::-webkit-scrollbar-thumb {
            background-color: #4a4a4a;
            border-radius: 4px;
        }
        
        /* Custom scrollbar for textarea */
        .scrollbar-hide::-webkit-scrollbar {
            display: none;
        }
        .scrollbar-hide {
            -ms-overflow-style: none; /* IE and Edge */
            scrollbar-width: none; /* Firefox */
        }

        /* Dotted background pattern */
        .bg-dots {
             background-image: radial-gradient(circle, #2a2a2a 1px, transparent 1px);
             background-size: 15px 15px;
        }

        /* Custom toggle checkbox */
        .toggle-checkbox:checked {
            @apply: bg-indigo-600;
        }
        .toggle-checkbox:checked::after {
            transform: translateX(20px);
        }
        .toggle-checkbox::after {
            content: '';
            @apply: absolute top-0.5 left-0.5 w-4 h-4 bg-white rounded-full shadow-md transition-transform duration-200 ease-in-out;
        }

        /* Chat message styling */
        .chat-message {
            display: flex;
            margin-bottom: 1rem;
        }
        .chat-message.user {
            justify-content: flex-end;
        }
        .chat-message.bot {
            justify-content: flex-start;
        }
        .message-content {
            max-width: 80%;
            padding: 0.75rem 1rem;
            border-radius: 12px;
            position: relative;
        }
        .chat-message.user .message-content {
            background-color: #4f46e5;
            color: white;
            border-bottom-right-radius: 4px;
        }
        .chat-message.bot .message-content {
            background-color: #2a2a2a; /* dark:bg-dark-bg-tertiary */
            color: #e0e0e0; /* dark:text-dark-text */
            border: 1px solid #3a3a3a; /* dark:border-dark-border */
            border-bottom-left-radius: 4px;
        }
        .message-content p {
            margin: 0;
            white-space: pre-wrap;
            word-wrap: break-word;
        }
        /* Markdown formatting */
        .message-content strong { font-weight: bold; }
        .message-content em { font-style: italic; }
        .message-content code {
            font-family: 'Courier New', Courier, monospace;
            background-color: #1e1e1e; /* dark:bg-dark-bg-secondary */
            padding: 2px 5px;
            border-radius: 4px;
            font-size: 0.9em;
        }
        .message-content pre {
            background-color: #1e1e1e;
            padding: 0.75rem;
            border-radius: 8px;
            margin: 0.5rem 0;
            overflow-x: auto;
            border: 1px solid #3a3a3a;
        }
        .message-content pre code {
            background-color: transparent;
            padding: 0;
        }
        .message-content ul, .message-content ol {
            padding-left: 1.5rem;
            margin: 0.5rem 0;
        }
        .message-content li {
            margin-bottom: 0.25rem;
        }
        
        /* Citation/Source styling */
        .source-container {
            margin-top: 0.75rem;
            padding-top: 0.75rem;
            border-top: 1px solid #3a3a3a; /* dark:border-dark-border */
        }
        .source-title {
            font-size: 0.8rem;
            font-weight: bold;
            color: #a0a0a0; /* dark:text-dark-text-secondary */
            margin-bottom: 0.25rem;
        }
        .source-list {
            display: flex;
            flex-wrap: wrap;
            gap: 0.5rem;
        }
        .source-item {
            display: inline-block;
            font-size: 0.75rem;
            padding: 0.25rem 0.5rem;
            background-color: #3a3a3a;
            color: #e0e0e0;
            border-radius: 99px;
            text-decoration: none;
            transition: background-color 0.2s;
        }
        .source-item:hover {
            background-color: #4f46e5;
            color: white;
        }
        
        /* Microphone recording animation */
        #mic-btn.is-recording {
            color: #ef4444; /* red-500 */
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.6; }
        }
    </style>

    <!-- Main Application Logic -->
    <script type="module">
        // --- Global State ---
        let GEMINI_API_KEY = "";
        let chatHistory = [];
        let attachedFile = null; // { base64: "...", mimeType: "..." }
        let speechRecognition;
        let isRecording = false;
        let ttsAudioQueue = [];
        let isPlayingTTS = false;
        
        // --- DOM Elements ---
        const chatContainer = document.getElementById('chat-container');
        const chatForm = document.getElementById('chat-form');
        const promptInput = document.getElementById('prompt-input');
        const sendBtn = document.getElementById('send-btn');
        const sendIcon = document.getElementById('send-icon');
        const loadingSpinner = document.getElementById('loading-spinner');
        const micBtn = document.getElementById('mic-btn');
        const fileUploadBtn = document.getElementById('file-upload-btn');
        const fileUploadInput = document.getElementById('file-upload-input');
        const filePreviewContainer = document.getElementById('file-preview-container');
        const filePreviewImage = document.getElementById('file-preview-image');
        const removeFileBtn = document.getElementById('remove-file-btn');
        const googleSearchToggle = document.getElementById('google-search-toggle');
        const voiceResponseToggle = document.getElementById('voice-response-toggle');
        const errorMessage = document.getElementById('error-message');
        const errorText = document.getElementById('error-text');

        // --- Core Functions ---

        /**
         * Initializes the application.
         * Tries to find the API key first from Netlify's meta tag,
         * then falls back to the local config.js.
         */
        function initializeApp() {
            // 1. Try to get API key from Netlify's injected meta tag
            const metaTag = document.querySelector('meta[name="gemini-api-key"]');
            
            if (metaTag && metaTag.content && metaTag.content !== "${GEMINI_API_KEY}") {
                GEMINI_API_KEY = metaTag.content;
                console.log("API Key loaded from meta tag.");
            } 
            // 2. If not found, fall back to local config.js (for localhost)
            else if (typeof GEMINI_API_KEY_LOCAL !== 'undefined') {
                GEMINI_API_KEY = GEMINI_API_KEY_LOCAL;
                console.log("API Key loaded from local config.js.");
            } 
            // 3. If still not found, show an error.
            else {
                let errorHtml = "";
                // This logic creates a more specific error message.
                if (window.location.hostname === "localhost" || window.location.hostname === "127.0.0.1") {
                    errorHtml = "<b>API Key not found for local development.</b><br>Please ensure you have a `config.js` file in the root directory with the content: `const GEMINI_API_KEY_LOCAL = \"YOUR_KEY_HERE\";`";
                } else if (metaTag && metaTag.content === "${GEMINI_API_KEY}") {
                    errorHtml = "<b>API Key not configured.</b> <b>Snippet injection is working, but Environment Variable is not.</b><br>Please check two things in Netlify:<br>1. The variable <b>Key</b> is spelled *exactly* `GEMINI_API_KEY` (with an underscore).<br>2. You clicked \"Clear cache and deploy site\" *after* saving the variable.";
                } else {
                    errorHtml = "<b>API Key not configured.</b><br>Could not find `meta[name=\"gemini-api-key\"]` tag. Please check your Snippet Injection settings in Netlify.";
                }
                showError(errorHtml);
                console.error("API Key not found. Looked for meta-tag (deploy) and config.js (local).");
            }

            // Initialize Speech Recognition if available
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (SpeechRecognition) {
                speechRecognition = new SpeechRecognition();
                speechRecognition.continuous = false;
                speechRecognition.interimResults = false;
                speechRecognition.lang = 'en-US';

                speechRecognition.onresult = (event) => {
                    const transcript = event.results[0][0].transcript;
                    promptInput.value = transcript;
                    stopRecording();
                    handleChatSubmit(); // Automatically send after transcription
                };

                speechRecognition.onerror = (event) => {
                    console.error("Speech recognition error:", event.error);
                    showError("Speech recognition error: " + event.error);
                    stopRecording();
                };
                
                speechRecognition.onend = () => {
                    stopRecording();
                };

            } else {
                console.warn("Speech Recognition not supported in this browser.");
                micBtn.disabled = true;
                micBtn.title = "Microphone not supported in this browser";
                micBtn.classList.add("opacity-50", "cursor-not-allowed");
            }
        }
        
        /**
         * Main function to handle chat submission.
         * Gathers all data and sends it to the Gemini API.
         */
        async function handleChatSubmit() {
            const userPrompt = promptInput.value.trim();

            // Don't send if prompt is empty and no file is attached
            if (!userPrompt && !attachedFile) {
                return;
            }

            // Disable UI
            setLoadingState(true);
            hideError();

            // 1. Add user's message to chat
            const userMessageId = `msg-${Date.now()}`;
            addMessageToChat('user', userPrompt || "Uploaded a file", userMessageId);

            // 2. Prepare API payload
            const model = "gemini-2.5-flash-preview-09-2025";
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${GEMINI_API_KEY}`;
            
            const payload = {
                contents: [],
                tools: [],
                systemInstruction: {
                    parts: [{ text: "You are a helpful, creative, and friendly AI assistant. Answer the user's request, but if you use sources, you *must* cite them. Your response should be formatted in Markdown." }]
                }
            };

            // 2a. Add chat history
            // We'll add this *after* the current prompt for multimodel consistency
            
            // 2b. Add current prompt
            const userParts = [];
            if (userPrompt) {
                userParts.push({ text: userPrompt });
            }
            if (attachedFile) {
                userParts.push({
                    inlineData: {
                        mimeType: attachedFile.mimeType,
                        data: attachedFile.base64
                    }
                });
            }
            
            // Combine history and new prompt
            payload.contents = [
                ...chatHistory, // Add past messages
                { role: "user", parts: userParts } // Add new message
            ];
            
            // 2c. Add tools (Google Search)
            if (googleSearchToggle.checked) {
                payload.tools.push({ "google_search": {} });
            }

            // 3. Make the API call
            try {
                const response = await fetchWithBackoff(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                
                const result = await response.json();

                if (!response.ok || !result.candidates) {
                    const errorMsg = result.error ? `${result.error.message} (Code: ${result.error.status})` : "API returned an invalid response.";
                    throw new Error(errorMsg);
                }

                const candidate = result.candidates[0];
                const botResponseText = candidate.content.parts[0].text;
                
                // 4. Handle response
                const botMessageId = `msg-${Date.now() + 1}`;
                
                // 4a. Extract sources (if any)
                let sources = [];
                const groundingMetadata = candidate.groundingMetadata;
                if (groundingMetadata && groundingMetadata.groundingAttributions) {
                    sources = groundingMetadata.groundingAttributions
                        .map(attr => ({
                            uri: attr.web?.uri,
                            title: attr.web?.title,
                        }))
                        .filter(source => source.uri && source.title);
                }

                // 4b. Add bot message to chat
                addMessageToChat('bot', botResponseText, botMessageId, sources);

                // 4c. Update chat history for next turn
                chatHistory.push({ role: "user", parts: userParts });
                chatHistory.push({ role: "model", parts: candidate.content.parts });
                
                // 4d. Handle TTS
                if (voiceResponseToggle.checked) {
                    queueTTS(botResponseText);
                }

            } catch (error) {
                console.error("API Error:", error);
                showError(`Sorry, I encountered an error: ${error.message}`);
                addMessageToChat('bot', `Sorry, I encountered an error and couldn't process your request. \n\n**Error:** ${error.message}`, `err-${Date.now()}`);
            } finally {
                // 5. Re-enable UI
                setLoadingState(false);
                clearFileInput();
                promptInput.value = "";
                promptInput.style.height = 'auto'; // Reset height
            }
        }
        
        /**
         * Fetches with exponential backoff for rate limiting.
         */
        async function fetchWithBackoff(url, options, retries = 3, delay = 1000) {
            try {
                const response = await fetch(url, options);
                if (response.status === 429 && retries > 0) {
                    console.warn(`Rate limited. Retrying in ${delay / 1000}s...`);
                    await new Promise(resolve => setTimeout(resolve, delay));
                    return fetchWithBackoff(url, options, retries - 1, delay * 2);
                }
                return response;
            } catch (error) {
                if (retries > 0) {
                    console.warn(`Fetch error. Retrying in ${delay / 1000}s...`, error.message);
                    await new Promise(resolve => setTimeout(resolve, delay));
                    return fetchWithBackoff(url, options, retries - 1, delay * 2);
                }
                throw error;
            }
        }

        // --- UI Functions ---
        
        /**
         * Adds a message to the chat window.
         * @param {string} role - 'user' or 'bot'
         * @param {string} text - The message content
         * @param {string} id - A unique ID for the message element
         * @param {Array} sources - Array of source objects {uri, title}
         */
        function addMessageToChat(role, text, id, sources = []) {
            const messageElement = document.createElement('div');
            messageElement.className = `chat-message ${role}`;
            messageElement.id = id;
            
            const contentElement = document.createElement('div');
            contentElement.className = 'message-content';
            
            // Sanitize and format text using a simple Markdown-like parser
            contentElement.innerHTML = simpleMarkdownParser(text);
            
            // Add sources if they exist
            if (sources.length > 0) {
                const sourceContainer = document.createElement('div');
                sourceContainer.className = 'source-container';
                
                const sourceTitle = document.createElement('h4');
                sourceTitle.className = 'source-title';
                sourceTitle.textContent = 'Sources:';
                sourceContainer.appendChild(sourceTitle);
                
                const sourceList = document.createElement('div');
                sourceList.className = 'source-list';
                
                sources.forEach((source, index) => {
                    const sourceLink = document.createElement('a');
                    sourceLink.href = source.uri;
                    sourceLink.textContent = `${index + 1}. ${source.title}`;
                    sourceLink.className = 'source-item';
                    sourceLink.target = '_blank';
                    sourceLink.rel = 'noopener noreferrer';
                    sourceList.appendChild(sourceLink);
                });
                
                sourceContainer.appendChild(sourceList);
                contentElement.appendChild(sourceContainer);
            }
            
            messageElement.appendChild(contentElement);
            chatContainer.appendChild(messageElement);

            // Scroll to the new message
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        /**
         * A simple parser to convert Markdown to HTML.
         * This is safer than a full library and avoids XSS.
         */
        function simpleMarkdownParser(text) {
            let html = text
                .replace(/&/g, '&amp;')
                .replace(/</g, '&lt;')
                .replace(/>/g, '&gt;');
            
            // **Bold**
            html = html.replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>');
            // *Italic*
            html = html.replace(/\*(.*?)\*/g, '<em>$1</em>');
            // `Code`
            html = html.replace(/`(.*?)`/g, '<code>$1</code>');
            // ```Block```
            html = html.replace(/```([\s\S]*?)```/g, (match, code) => {
                const escapedCode = code.replace(/&/g, '&amp;').replace(/</g, '&lt;').replace(/>/g, '&gt;');
                return `<pre><code>${escapedCode}</code></pre>`;
            });
            // * List item
            html = html.replace(/^\* (.*$)/gm, '<ul><li>$1</li></ul>');
            // 1. List item
            html = html.replace(/^\d+\. (.*$)/gm, '<ol><li>$1</li></ol>');
            // Fix stacked lists
            html = html.replace(/<\/ul>\n<ul>/g, '');
            html = html.replace(/<\/ol>\n<ol>/g, '');
            
            // Newlines
            html = html.replace(/\n/g, '<br>');

            return html;
        }

        /**
         * Toggles the UI state between loading and idle.
         * @param {boolean} isLoading - True to show loading, false to show idle.
         */
        function setLoadingState(isLoading) {
            sendBtn.disabled = isLoading;
            promptInput.disabled = isLoading;
            micBtn.disabled = isLoading;
            fileUploadBtn.disabled = isLoading;

            if (isLoading) {
                sendIcon.classList.add('hidden');
                loadingSpinner.classList.remove('hidden');
            } else {
                sendIcon.classList.remove('hidden');
                loadingSpinner.classList.add('hidden');
            }
        }
        
        /**
         * Shows an error message in the UI.
         * @param {string} message - The error message (can be HTML)
         */
        function showError(message) {
            errorText.innerHTML = message;
            errorMessage.classList.remove('hidden');
        }

        /** Hides the error message box. */
        function hideError() {
            errorMessage.classList.add('hidden');
        }

        // --- File Handling ---

        /**
         * Handles the selection of a file.
         * Reads the file as Base64 and displays a preview.
         */
        function handleFileSelect(event) {
            const file = event.target.files[0];
            if (!file) {
                return;
            }

            // For now, we only *really* support images for inlineData.
            // PDFs would require a different API.
            if (file.type.startsWith('image/')) {
                const reader = new FileReader();
                reader.onload = (e) => {
                    const base64Data = e.target.result.split(',')[1];
                    attachedFile = {
                        base64: base64Data,
                        mimeType: file.type
                    };
                    
                    // Show image preview
                    filePreviewImage.src = e.target.result;
                    filePreviewContainer.classList.remove('hidden');
                };
                reader.readAsDataURL(file);
            } else {
                // Handle non-image files (e.g., PDF)
                showError(`File type not fully supported. Only images can be analyzed. You can still *mention* the file in your prompt.`);
                // We'll just show a generic icon or name
                filePreviewImage.src = `https://placehold.co/128x128/2a2a2a/e0e0e0?text=${file.name.split('.').pop()}`;
                filePreviewContainer.classList.remove('hidden');
                // Don't set attachedFile, as we can't send non-image data
            }
        }
        
        /** Clears the attached file and hides the preview. */
        function clearFileInput() {
            attachedFile = null;
            fileUploadInput.value = null; // Clear the input
            filePreviewContainer.classList.add('hidden');
            filePreviewImage.src = "";
        }

        // --- Speech & TTS ---

        /** Toggles the microphone recording on and off. */
        function toggleRecording() {
            if (isRecording) {
                stopRecording();
            } else {
                startRecording();
            }
        }
        
        /** Starts the speech recognition. */
        function startRecording() {
            if (speechRecognition) {
                isRecording = true;
                micBtn.classList.add('is-recording');
                micBtn.title = "Stop Recording";
                promptInput.placeholder = "Listening...";
                speechRecognition.start();
            }
        }
        
        /** Stops the speech recognition. */
        function stopRecording() {
            if (speechRecognition) {
                isRecording = false;
                micBtn.classList.remove('is-recording');
                micBtn.title = "Use Microphone";
                promptInput.placeholder = "Type your message or use microphone...";
                speechRecognition.stop();
            }
        }
        
        /**
         * Queues a text string for Text-to-Speech.
         * @param {string} text - The text to be spoken.
         */
        function queueTTS(text) {
            // Split text into smaller chunks for better API response time
            // Simple split by sentences.
            const sentences = text.split(/(?<!\w\.\w.)(?<![A-Z][a-z]\.)(?<=\.|\?|!)\s/);
            
            for (const sentence of sentences) {
                if (sentence.trim().length > 0) {
                    ttsAudioQueue.push(sentence);
                }
            }
            
            if (!isPlayingTTS) {
                playNextTTS();
            }
        }

        /**
         * Plays the next item in the TTS queue.
         */
        async function playNextTTS() {
            if (ttsAudioQueue.length === 0) {
                isPlayingTTS = false;
                return;
            }
            
            isPlayingTTS = true;
            const text = ttsAudioQueue.shift();
            
            try {
                const audioData = await getTTSAudio(text);
                const audioUrl = await convertPcmToWavUrl(audioData);
                
                const audio = new Audio(audioUrl);
                audio.play();
                
                audio.onended = () => {
                    URL.revokeObjectURL(audioUrl); // Clean up
                    playNextTTS(); // Play the next item
                };
                
                audio.onerror = (e) => {
                    console.error("Error playing TTS audio:", e);
                    playNextTTS(); // Skip to next item on error
                };

            } catch (error) {
                console.error("Failed to get or play TTS:", error);
                playNextTTS(); // Skip to next item on error
            }
        }
        
        /**
         * Fetches PCM audio data from the TTS API.
         * @param {string} text - The text to synthesize.
         * @returns {string} - Base64 encoded PCM audio data.
         */
        async function getTTSAudio(text) {
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${GEMINI_API_KEY}`;
            
            const payload = {
                contents: [{
                    parts: [{ text: `Say in a casual, friendly tone: ${text}` }]
                }],
                generationConfig: {
                    responseModalities: ["AUDIO"],
                    speechConfig: {
                        speechConfig: {
                            voiceConfig: { prebuiltVoiceConfig: { voiceName: "Puck" } }
                        }
                    }
                },
                model: "gemini-2.5-flash-preview-tts"
            };

            const response = await fetchWithBackoff(apiUrl, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });
            
            const result = await response.json();
            
            if (!response.ok || !result.candidates) {
                throw new Error(result.error ? result.error.message : "Invalid TTS response");
            }
            
            const part = result.candidates[0].content.parts[0];
            if (!part.inlineData || !part.inlineData.data) {
                throw new Error("No audio data in TTS response");
            }
            
            return part.inlineData.data;
        }

        /**
         * Converts Base64 PCM data into a playable WAV Blob URL.
         * @param {string} base64Pcm - Base64 encoded PCM data.
         * @returns {string} - A Blob URL for the WAV audio.
         */
        async function convertPcmToWavUrl(base64Pcm) {
            // 1. Decode Base64 to ArrayBuffer
            const binaryString = window.atob(base64Pcm);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            const pcmData = bytes.buffer;
            
            // 2. The API returns 16-bit PCM at 24000Hz, single channel
            const sampleRate = 24000;
            const numChannels = 1;
            const bitsPerSample = 16;
            const pcm16 = new Int16Array(pcmData);

            // 3. Create WAV Header
            const wavHeader = new ArrayBuffer(44);
            const view = new DataView(wavHeader);
            
            const dataSize = pcm16.length * 2;
            const fileSize = dataSize + 36;
            
            view.setUint32(0, 0x52494646, false); // "RIFF"
            view.setUint32(4, fileSize, true); // File size - 8
            view.setUint32(8, 0x57415645, false); // "WAVE"
            view.setUint32(12, 0x666d7420, false); // "fmt "
            view.setUint32(16, 16, true); // Subchunk1 size (16 for PCM)
            view.setUint16(20, 1, true); // Audio format (1 for PCM)
            view.setUint16(22, numChannels, true); // Num channels
            view.setUint32(24, sampleRate, true); // Sample rate
            view.setUint32(28, sampleRate * numChannels * (bitsPerSample / 8), true); // Byte rate
            view.setUint16(32, numChannels * (bitsPerSample / 8), true); // Block align
            view.setUint16(34, bitsPerSample, true); // Bits per sample
            view.setUint32(36, 0x64617461, false); // "data"
            view.setUint32(40, dataSize, true); // Subchunk2 size
            
            // 4. Create Blob
            const wavBlob = new Blob([wavHeader, pcm16], { type: 'audio/wav' });
            return URL.createObjectURL(wavBlob);
        }
        
        // --- Event Listeners ---

        // Auto-resize textarea
        promptInput.addEventListener('input', () => {
            promptInput.style.height = 'auto'; // Reset height
            promptInput.style.height = (promptInput.scrollHeight) + 'px';
        });

        // Submit form on Enter (but not Shift+Enter)
        promptInput.addEventListener('keydown', (e) => {
            if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault(); // Prevent newline
                handleChatSubmit();
            }
        });
        
        // Submit form on button click
        chatForm.addEventListener('submit', (e) => {
            e.preventDefault();
            handleChatSubmit();
        });

        // Toggle microphone
        micBtn.addEventListener('click', toggleRecording);
        
        // Trigger file input
        fileUploadBtn.addEventListener('click', () => {
            fileUploadInput.click();
        });
        
        // Handle file selection
        fileUploadInput.addEventListener('change', handleFileSelect);
        
        // Remove attached file
        removeFileBtn.addEventListener('click', clearFileInput);
        
        // --- Initialization ---
        initializeApp();

    </script>
</body>
</html>